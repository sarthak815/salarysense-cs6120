{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "eda = pd.read_csv('raw_glassdoor_data/eda_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_cols = [\n",
    "    'Company Name', 'Headquarters', 'Size', 'Founded', \n",
    "    'Type of ownership', 'Industry', 'Sector', 'Revenue', \n",
    "    'Competitors', 'company_txt', 'Rating'\n",
    "]\n",
    "\n",
    "companies_df = eda[company_cols].drop_duplicates(subset=['Company Name']).copy()\n",
    "companies_df.reset_index(drop=True, inplace=True)\n",
    "companies_df['company_id'] = companies_df.index + 1\n",
    "\n",
    "companies_df = companies_df[['company_id'] + company_cols]\n",
    "\n",
    "companies_df.drop(columns=['Company Name'], inplace=True)\n",
    "companies_df.rename(columns={'company_txt': 'Company Name'}, inplace=True)\n",
    "companies_df.rename(columns={'Rating': 'Company Rating'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies with more than one unique Industry:\n",
      "Empty DataFrame\n",
      "Columns: [clean_company_name, unique_industries]\n",
      "Index: []\n",
      "\n",
      "Companies with more than one unique Sector:\n",
      "Empty DataFrame\n",
      "Columns: [clean_company_name, unique_sectors]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#remove any appended ratings\n",
    "eda['clean_company_name'] = eda['Company Name'].apply(lambda x: x.split(\"\\n\")[0].strip())\n",
    "\n",
    "#variations in industry column, can one company have multiple industries?\n",
    "industries = eda.groupby('clean_company_name')['Industry'].nunique().reset_index(name='unique_industries')\n",
    "companies_with_many_industries = industries[industries['unique_industries'] > 1]\n",
    "print(companies_with_many_industries)\n",
    "\n",
    "#can one company have multiple sectors?\n",
    "sectors = eda.groupby('clean_company_name')['Sector'].nunique().reset_index(name='unique_sectors')\n",
    "companies_with_many_sectors = sectors[sectors['unique_sectors'] > 1]\n",
    "print(companies_with_many_sectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'Job Title', 'Salary Estimate', 'Job Description', \n",
    "    'hourly', 'employer_provided',\n",
    "    'min_salary', 'max_salary', 'avg_salary', 'age',\n",
    "    'python_yn', 'R_yn', 'spark', 'aws', 'excel', \n",
    "    'job_simp', 'seniority', 'num_comp'\n",
    "]\n",
    "\n",
    "jobs_df = eda[columns].copy()\n",
    "\n",
    "jobs_df['Company Name'] = eda['company_txt']\n",
    "\n",
    "#merge jobs_df with companies_df to get the corresponding company_id.\n",
    "#companies_df has been built using the clean company name in Company Name column\n",
    "jobs_df = jobs_df.merge(companies_df[['company_id', 'Company Name']], on='Company Name', how='left')\n",
    "\n",
    "\n",
    "jobs_df.drop(columns=['Company Name'], inplace=True)\n",
    "\n",
    "#create job id starting from 1\n",
    "jobs_df['job_id'] = range(1, len(jobs_df) + 1)\n",
    "\n",
    "#rearranging columns to have job_id as the first column\n",
    "cols = ['job_id'] + [col for col in jobs_df.columns if col != 'job_id']\n",
    "jobs_df = jobs_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove salary estimate column\n",
    "jobs_df.drop(columns=['Salary Estimate'], inplace=True)\n",
    "\n",
    "\n",
    "hourly = jobs_df['hourly'] == 1\n",
    "others = jobs_df['hourly'] == 0\n",
    "\n",
    "#convert hourly rate to annual salary by multiplying by 40*52 (2,080)\n",
    "jobs_df.loc[hourly, 'min_salary'] = jobs_df.loc[hourly, 'min_salary'] * (40 * 52)\n",
    "jobs_df.loc[hourly, 'max_salary'] = jobs_df.loc[hourly, 'max_salary'] * (40 * 52)\n",
    "jobs_df.loc[hourly, 'avg_salary'] = jobs_df.loc[hourly, 'avg_salary'] * (40 * 52)\n",
    "\n",
    "#for jobs that are not hourly, they are already in thousands, ex: 120 represents 120,000. we need to conver them multiplying by 1,000\n",
    "jobs_df.loc[others, 'min_salary'] = jobs_df.loc[others, 'min_salary'] * 1000\n",
    "jobs_df.loc[others, 'max_salary'] = jobs_df.loc[others, 'max_salary'] * 1000\n",
    "jobs_df.loc[others, 'avg_salary'] = jobs_df.loc[others, 'avg_salary'] * 1000\n",
    "\n",
    "#drop the hourly column as it is no longer needed\n",
    "jobs_df.drop(columns=['hourly'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   job_id                  Job Title  \\\n",
      "0       1             Data Scientist   \n",
      "1       2  Healthcare Data Scientist   \n",
      "2       3             Data Scientist   \n",
      "3       4             Data Scientist   \n",
      "4       5             Data Scientist   \n",
      "\n",
      "                                     Job Description  employer_provided  \\\n",
      "0  Data Scientist\\nLocation: Albuquerque, NM\\nEdu...                  0   \n",
      "1  What You Will Do:\\n\\nI. General Summary\\n\\nThe...                  0   \n",
      "2  KnowBe4, Inc. is a high growth information sec...                  0   \n",
      "3  *Organization and Job ID**\\nJob ID: 310709\\n\\n...                  0   \n",
      "4  Data Scientist\\nAffinity Solutions / Marketing...                  0   \n",
      "\n",
      "   min_salary  max_salary  avg_salary  age  Python  R  Spark  AWS  Excel  \\\n",
      "0       53000       91000     72000.0   47       1  0      0    0      1   \n",
      "1       63000      112000     87500.0   36       1  0      0    0      0   \n",
      "2       80000       90000     85000.0   10       1  0      1    0      1   \n",
      "3       56000       97000     76500.0   55       1  0      0    0      0   \n",
      "4       86000      143000    114500.0   22       1  0      0    0      1   \n",
      "\n",
      "         job_simp seniority  num_comp  company_id  \n",
      "0  data scientist        na         0           1  \n",
      "1  data scientist        na         0           2  \n",
      "2  data scientist        na         0           3  \n",
      "3  data scientist        na         3           4  \n",
      "4  data scientist        na         3           5  \n"
     ]
    }
   ],
   "source": [
    "#rename the columns to be more descriptive\n",
    "jobs_df.rename(columns={\n",
    "    'python_yn': 'Python',\n",
    "    'R_yn': 'R',\n",
    "    'spark': 'Spark',\n",
    "    'aws': 'AWS',\n",
    "    'excel': 'Excel'\n",
    "}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_factor = 1.314  #for 2017->2025\n",
    "\n",
    "#use inflation factor to adjust salaries\n",
    "jobs_df['min_salary'] = jobs_df['min_salary'] * inflation_factor\n",
    "jobs_df['max_salary'] = jobs_df['max_salary'] * inflation_factor\n",
    "jobs_df['avg_salary'] = jobs_df['avg_salary'] * inflation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   job_id                  Job Title  \\\n",
      "0       1             Data Scientist   \n",
      "1       2  Healthcare Data Scientist   \n",
      "2       3             Data Scientist   \n",
      "3       4             Data Scientist   \n",
      "4       5             Data Scientist   \n",
      "\n",
      "                                     Job Description seniority  company_id  \\\n",
      "0  Data Scientist\\nLocation: Albuquerque, NM\\nEdu...        na           1   \n",
      "1  What You Will Do:\\n\\nI. General Summary\\n\\nThe...        na           2   \n",
      "2  KnowBe4, Inc. is a high growth information sec...        na           3   \n",
      "3  *Organization and Job ID**\\nJob ID: 310709\\n\\n...        na           4   \n",
      "4  Data Scientist\\nAffinity Solutions / Marketing...        na           5   \n",
      "\n",
      "   age  Python  R  Spark  AWS  Excel  min_salary  max_salary  avg_salary  \\\n",
      "0   47       1  0      0    0      1     69642.0    119574.0     94608.0   \n",
      "1   36       1  0      0    0      0     82782.0    147168.0    114975.0   \n",
      "2   10       1  0      1    0      1    105120.0    118260.0    111690.0   \n",
      "3   55       1  0      0    0      0     73584.0    127458.0    100521.0   \n",
      "4   22       1  0      0    0      1    113004.0    187902.0    150453.0   \n",
      "\n",
      "   employer_provided  num_comp  \n",
      "0                  0         0  \n",
      "1                  0         0  \n",
      "2                  0         0  \n",
      "3                  0         3  \n",
      "4                  0         3  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_order = [\n",
    "    'job_id', \n",
    "    'Job Title', \n",
    "    'Job Description', \n",
    "    'seniority', \n",
    "    'company_id', \n",
    "    'age', \n",
    "    'Python', \n",
    "    'R', \n",
    "    'Spark', \n",
    "    'AWS', \n",
    "    'Excel', \n",
    "    'min_salary', \n",
    "    'max_salary', \n",
    "    'avg_salary', \n",
    "    'employer_provided',\n",
    "    'num_comp'\n",
    "]\n",
    "\n",
    "# Reorder the DataFrame accordingly\n",
    "jobs_df = jobs_df[columns_order]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.to_csv(\"glassdoor_jobs.csv\", index=False)\n",
    "\n",
    "companies_df.to_csv(\"glassdoor_companies.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
